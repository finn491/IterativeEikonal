{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IterativeEikonal\n",
    "Approximate the viscosity solution of the  Eikonal equation \n",
    "$$\\begin{cases} \\Vert \\nabla_G W(g) \\Vert = 1, & g \\in G \\setminus S, \\\\\n",
    "W(g) = 0, & g \\in S \\subset G. \\end{cases}$$\n",
    "This method is based on the paper [\"A PDE Approach to Data-Driven Sub-Riemannian Geodesics in $SE(2)$\" (2015) by E. J. Bekkers, R. Duits, A. Mashtakov, and G. R. Sanguinetti](https://doi.org/10.1137/15M1018460)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import iterativeeikonal as eik\n",
    "import taichi as ti\n",
    "ti.init(arch=ti.gpu, debug=False)\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\mathbb{R}^2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flat space\n",
    "In fact, we will solve the Eikonal equation on some subset $G \\subset \\mathbb{R}^2$, namely $G = [-1, 1] \\times [-1, 1]$. The source set will consist of a single point: $S = \\{(0, 0)\\}$. Then we know that the viscosity solution is simply the Euclidean norm. \n",
    "\n",
    "There are numerous ways to numerically solve the Eikonal equation. We could use [Fast Marching](https://en.wikipedia.org/wiki/Fast_marching_method). This is an efficient method, but it requires a lot of work to make it compatible with non-Euclidean domains. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_marching_R2(f):\n",
    "    \"\"\"\n",
    "    Naive implementation of fast marching to solve Eikonal equation on R2 with \n",
    "    cost `f`.\"\"\"\n",
    "    N = f.shape[0]\n",
    "    f = pad_array(f, 1.)\n",
    "    dxy = 2. / N\n",
    "    point_stages = 2 * np.ones((N, N), dtype=int)\n",
    "    W = np.full(shape=(N, N), fill_value=100.)\n",
    "    point_stages = pad_array(point_stages, 0)\n",
    "    W = pad_array(W, 100.)\n",
    "    i_0, j_0 = ((N + 1) // 2, (N + 1) // 2)\n",
    "    point_stages[i_0, j_0] = 0\n",
    "    W[i_0, j_0] = 0\n",
    "    i_star, j_star = i_0, j_0\n",
    "    while np.any(point_stages != 0):\n",
    "        update_neighbours(i_star, j_star, point_stages, W, dxy, f)\n",
    "        Trial = point_stages == 1\n",
    "        index = np.argmin(np.where(Trial, W, np.inf))\n",
    "        i_star, j_star = np.unravel_index(index, W.shape)\n",
    "        point_stages[i_star, j_star] = 0\n",
    "    return unpad_array(W)\n",
    "\n",
    "def pad_array(array, fill_value):\n",
    "    padded_shape = (array.shape[0] + 2, array.shape[1] + 2)\n",
    "    padded_array = np.ones(padded_shape, dtype=array.dtype) * fill_value\n",
    "    padded_array[1:-1, 1:-1] = array\n",
    "    return padded_array\n",
    "\n",
    "def unpad_array(padded_array):\n",
    "    return padded_array[1:-1, 1:-1]\n",
    "\n",
    "def update_neighbours(i_star, j_star, point_stages, W, dxy, f):\n",
    "    neighbours = sees_point(i_star, j_star)\n",
    "    for i, j in neighbours:\n",
    "        if point_stages[i, j] != 0:\n",
    "            point_stages[i, j] = 1\n",
    "            update_W(i, j, W, dxy, f)\n",
    "\n",
    "def update_W(i, j, W, dxy, f):\n",
    "    Wx, Wy = gradient_W(i, j, W)\n",
    "    if np.abs(Wx - Wy) >= dxy:\n",
    "        W[i, j] = np.min((Wx + dxy / f[i, j], Wy + dxy / f[i, j]))\n",
    "    else:\n",
    "        W[i, j] = (Wx + Wy + np.sqrt((Wx + Wy) ** 2 - 2 * (Wx ** 2 + Wy ** 2 - (dxy / f[i, j]) ** 2))) / 2\n",
    "\n",
    "def gradient_W(i, j, W):\n",
    "    Wx = min(W[i + 1, j], W[i - 1, j])\n",
    "    Wy = min(W[i, j + 1], W[i, j - 1])\n",
    "    return Wx, Wy\n",
    "\n",
    "def sees_point(i_star, j_star):\n",
    "    return ((i_star + 1, j_star), (i_star - 1, j_star), (i_star, j_star + 1), (i_star, j_star - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can alternatively apply an iterative method, developed by [Bekkers et al.](https://doi.org/10.1137/15M1018460)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_method_flat_R2(N, n):\n",
    "    \"\"\"\n",
    "    Discretise [-1, 1] x [-1, 1] into `N` points in each direction, and apply \n",
    "    the iterative solution method `n` times.\n",
    "    \"\"\"\n",
    "    dxy = 2. / (N + 1)\n",
    "    eps = dxy / 4\n",
    "\n",
    "    W = get_initial_W(N)\n",
    "    boundarypoints, boundaryvalues = get_boundary_conditions(N)\n",
    "\n",
    "    eik.cleanarrays.apply_boundary_conditions(W, boundarypoints, boundaryvalues)\n",
    "\n",
    "    dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy = get_initial_derivatives(W)\n",
    "    for _ in tqdm(range(n)):\n",
    "        step_W(W, dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy, dxy, eps)\n",
    "        eik.cleanarrays.apply_boundary_conditions(W, boundarypoints, boundaryvalues)\n",
    "\n",
    "    W_np = W.to_numpy()\n",
    "    return eik.cleanarrays.unpad_array(W_np)\n",
    "\n",
    "def get_initial_W(N, initial_condition=100.):\n",
    "    W_unpadded = np.full(shape=(N, N), fill_value=initial_condition)\n",
    "    W_np = eik.cleanarrays.pad_array(W_unpadded, pad_value=initial_condition, pad_shape=1)\n",
    "    W = ti.field(dtype=ti.f32, shape=W_np.shape)\n",
    "    W.from_numpy(W_np)\n",
    "    return W\n",
    "\n",
    "def get_boundary_conditions(N):\n",
    "    i_0, j_0 = (N + 1) // 2, (N + 1) // 2\n",
    "    boundarypoints_np = np.array([[i_0, j_0]], dtype=int)\n",
    "    boundaryvalues_np = np.array([0.], dtype=float)\n",
    "    boundarypoints = ti.Vector.field(n=2, dtype=ti.i32, shape=1)\n",
    "    boundarypoints.from_numpy(boundarypoints_np)\n",
    "    boundaryvalues = ti.field(shape=1, dtype=ti.f32)\n",
    "    boundaryvalues.from_numpy(boundaryvalues_np)\n",
    "    return boundarypoints, boundaryvalues\n",
    "\n",
    "def get_initial_derivatives(W):\n",
    "    dx_forward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dx_backward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dy_forward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dy_backward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    abs_dx = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    abs_dy = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    return dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy\n",
    "\n",
    "@ti.kernel\n",
    "def step_W(\n",
    "    W:ti.template(), \n",
    "    dx_forward: ti.template(), \n",
    "    dx_backward: ti.template(), \n",
    "    dy_forward: ti.template(), \n",
    "    dy_backward: ti.template(), \n",
    "    abs_dx: ti.template(), \n",
    "    abs_dy: ti.template(), \n",
    "    dxy: ti.f32, \n",
    "    eps: ti.f32\n",
    "):\n",
    "    eik.derivativesR2.abs_derivatives(W, dxy, dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy)\n",
    "    for I in ti.grouped(W):\n",
    "        W[I] += (1 - ti.math.sqrt(abs_dx[I] ** 2 + abs_dy[I] ** 2)) * eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 51\n",
    "n = 250\n",
    "xs, ys = np.meshgrid(np.linspace(-1, 1, N), np.linspace(-1, 1, N))\n",
    "W_exact = np.sqrt(xs ** 2 + ys ** 2)\n",
    "W_iterative_big = iterative_method_flat_R2(N, n)\n",
    "f = np.ones((N, N), dtype=float)\n",
    "W_fast_marching = fast_marching_R2(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(6, 5))\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "fig.canvas.resizable = False\n",
    "contour = ax.contour(xs, ys, W_fast_marching, linestyles=\"dotted\")\n",
    "contour = ax.contour(xs, ys, W_iterative_big, linestyles=\"dashed\")\n",
    "ax.contour(xs, ys, W_exact)\n",
    "ax.set_xlim(-1, 1)\n",
    "ax.set_ylim(-1, 1)\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "fig.colorbar(contour, label=\"W(x, y)\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retinal image\n",
    "Computing the cost function on flat $\\mathbb{R}^2$ is not very impressive. We would like to be able to do it also when the space is not flat, for instance in the case of a retinal image. To track the vessels in a retinal image, it makes sense to assign a low cost to those areas of the image that are vessels, and a high cost to those that aren't. We must therefore first compute such a cost function.\n",
    "\n",
    "To do this, we use Frangi vesselness filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Frangi vesselness filtering\n",
    "Let's first load in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = 8\n",
    "retinal_image = Image.open(\"E46_OD_best.tif\")\n",
    "width, height = retinal_image.size\n",
    "retinal_image_gray_ds = retinal_image.resize((width // ds, height // ds)).convert(\"L\")\n",
    "retinal_array_unnormalised = np.array(retinal_image_gray_ds).astype(np.float64)\n",
    "retinal_array = retinal_array_unnormalised / retinal_array_unnormalised.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will already define the start and the end of our geodesic (`source_point` and `target_point`, respectively)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_point = (246, 302) # \"y\", \"x\" so row, column.\n",
    "target_point = (211, 118)\n",
    "i_min, i_max = 0, retinal_array.shape[0] -1\n",
    "j_min, j_max = 0, retinal_array.shape[0] -1\n",
    "xs, ys = np.meshgrid(np.arange(i_min, i_max + 1), np.arange(j_min, j_max + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now perform the Frangi filtering. The values for the scales, as well as the Frangi filter parameters $\\alpha$, $\\gamma$, and $\\varepsilon$ were taken from the Mathematica notebook \"Code A - Vesselness in SE(2).nb\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scales = (np.array((2, 3, 4, 5), dtype=float))\n",
    "vesselness = eik.costfunctions.multiscale_frangi_filter_R2(-retinal_array, scales, α=0.3, γ=3/4, ε=0.3)\n",
    "mask = (retinal_array > 0) # Remove boundary\n",
    "vesselness *= sp.ndimage.binary_erosion(mask, iterations=int(np.ceil(scales.max() * 2)))\n",
    "print(f\"Before rescaling, vesselness is in [{vesselness.min()}, {vesselness.max()}].\")\n",
    "vesselness /= vesselness.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_vesselness = eik.cleanarrays.convert_array_to_image(vesselness)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "ax.imshow(image_vesselness, cmap=\"gray\", origin=\"upper\")\n",
    "ax.scatter(xs[source_point], ys[source_point], label=\"Source\", marker=\".\")\n",
    "ax.scatter(xs[target_point], ys[target_point], label=\"Target\", marker=\".\")\n",
    "ax.set_xlabel(\"j\")\n",
    "ax.set_ylabel(\"i\")\n",
    "ax.set_xlim(j_min, j_max)\n",
    "ax.set_ylim(i_max, i_min)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With these parameters, the vesselness score produced by the Frangi filter looks similar to the one in the Mathematica notebook \"code A - Vesselness in SE(2).nb\". However, the normalisation is not the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cost function\n",
    "Given the vesselness function, we compute the cost function as\n",
    "$$\\mathrm{cost}_{\\lambda, p}(x, y) = \\frac{1}{1 + \\lambda \\cdot \\vert \\mathrm{vesselness} \\vert^p}$$\n",
    "We choose $p = 2$, like in the Mathematica notebook, but $\\lambda = 100$ instead of $\\lambda = 1000$. This produces a cost function that looks more similar (probably due to the difference in normalisation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cost = eik.costfunctions.cost_function(vesselness, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_cost = eik.cleanarrays.convert_array_to_image(cost)\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(10, 10))\n",
    "ax.imshow(image_cost, cmap=\"gray\", origin=\"upper\")\n",
    "ax.scatter(xs[source_point], ys[source_point], label=\"Source\", marker=\".\")\n",
    "ax.scatter(xs[target_point], ys[target_point], label=\"Target\", marker=\".\")\n",
    "ax.set_xlabel(\"j\")\n",
    "ax.set_ylabel(\"i\")\n",
    "ax.set_xlim(j_min, j_max)\n",
    "ax.set_ylim(i_max, i_min)\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distance map\n",
    "We are now able to compute the distance map, which is the viscosity solution of the Eikonal equation\n",
    "$$\\begin{cases} \\Vert \\nabla_{\\mathrm{cost}} W(x, y) \\Vert = 1, & (x, y) \\in \\mathbb{R}^2 \\setminus \\{(x_0, y_0)\\}, \\\\\n",
    "W(x, y) = 0, & (x, y) = (x_0, y_0), \\end{cases}$$\n",
    "where $\\nabla_C$ is a datadriven derivative:\n",
    "$$\\Vert \\nabla_{\\mathrm{cost}} W(x, y) \\Vert = \\sqrt{\\mathrm{cost}_{\\lambda, p}^{-2}(x, y) (\\vert \\partial_x W(x, y) \\vert^2 + \\vert \\partial_y W(x, y) \\vert^2)}.$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iterative_method_retinal_R2(cost_np, source_point, target_point):\n",
    "    \"\"\"\n",
    "    Solve the Eikonal PDE on R2, with source at `source_point` and metric \n",
    "    defined by `cost_np`, using the iterative method described in Bekkers et al.\n",
    "    \"A PDE approach to Data-Driven Sub-Riemannian Geodesics in SE(2)\" (2015).\n",
    "\n",
    "    Args:\n",
    "        `cost_np`: np.ndarray of cost function.\n",
    "        `source_point`: Tuple[int] describing index of source point in \n",
    "          `cost_np`.\n",
    "        `target_point`: Tuple[int] describing index of target point in \n",
    "          `cost_np`.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of (approximate) distance map with respect to the cost \n",
    "          function described by `cost_np`.\n",
    "    \"\"\"\n",
    "    N = cost_np.shape[0]\n",
    "    ε = cost_np.min()\n",
    "\n",
    "    cost = get_padded_cost(cost_np)\n",
    "    W = get_initial_W(N)\n",
    "    boundarypoints, boundaryvalues = get_boundary_conditions(source_point)\n",
    "\n",
    "    eik.cleanarrays.apply_boundary_conditions(W, boundarypoints, boundaryvalues)\n",
    "\n",
    "    dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy, dW_dt = get_initial_derivatives(W)\n",
    "    step_size_target = 100.\n",
    "    tol = 1e-5 # What is a good stopping criterion?\n",
    "    n = 0\n",
    "    n_max = 1e5\n",
    "    while (np.abs(step_size_target) > tol) and (n <= n_max):\n",
    "        step_size_target = step_W(W, cost, dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy, ε, dW_dt, \n",
    "                                  target_point[0] + 1, target_point[1] + 1)\n",
    "        eik.cleanarrays.apply_boundary_conditions(W, boundarypoints, boundaryvalues)\n",
    "        n += 1\n",
    "    print(f\"Converged after {n - 1} steps!\")\n",
    "    print(step_size_target)\n",
    "    \n",
    "    W_np = W.to_numpy()\n",
    "    return eik.cleanarrays.unpad_array(W_np)\n",
    "\n",
    "def get_padded_cost(cost_unpadded):\n",
    "    \"\"\"Pad the cost function `cost_unpadded` and convert to TaiChi object.\"\"\"\n",
    "    cost_np = eik.cleanarrays.pad_array(cost_unpadded, pad_value=1., pad_shape=1)\n",
    "    cost = ti.field(dtype=ti.f32, shape=cost_np.shape)\n",
    "    cost.from_numpy(cost_np)\n",
    "    return cost\n",
    "\n",
    "def get_initial_W(N, initial_condition=100.):\n",
    "    \"\"\"Initialise the (approximate) distance map as TaiChi object.\"\"\"\n",
    "    W_unpadded = np.full(shape=(N, N), fill_value=initial_condition)\n",
    "    W_np = eik.cleanarrays.pad_array(W_unpadded, pad_value=initial_condition, pad_shape=1)\n",
    "    W = ti.field(dtype=ti.f32, shape=W_np.shape)\n",
    "    W.from_numpy(W_np)\n",
    "    return W\n",
    "\n",
    "def get_boundary_conditions(source_point):\n",
    "    \"\"\"\n",
    "    Determine the boundary conditions from `source_point`, giving the boundary\n",
    "    points and boundary values as TaiChi objects.\n",
    "    \"\"\"\n",
    "    i_0, j_0 = source_point\n",
    "    boundarypoints_np = np.array([[i_0, j_0]], dtype=int)\n",
    "    boundaryvalues_np = np.array([0.], dtype=float)\n",
    "    boundarypoints = ti.Vector.field(n=2, dtype=ti.i32, shape=1)\n",
    "    boundarypoints.from_numpy(boundarypoints_np)\n",
    "    boundaryvalues = ti.field(shape=1, dtype=ti.f32)\n",
    "    boundaryvalues.from_numpy(boundaryvalues_np)\n",
    "    return boundarypoints, boundaryvalues\n",
    "\n",
    "def get_initial_derivatives(W):\n",
    "    \"\"\"\n",
    "    Initialise empty TaiChi objects for the various derivatives of the \n",
    "    (approximate) distance map.\n",
    "    \"\"\"\n",
    "    dx_forward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dx_backward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dy_forward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dy_backward = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    abs_dx = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    abs_dy = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    dW_dt = ti.field(dtype=ti.f32, shape=W.shape)\n",
    "    return dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy, dW_dt\n",
    "\n",
    "@ti.kernel\n",
    "def step_W(\n",
    "    W: ti.template(), \n",
    "    cost: ti.template(),\n",
    "    dx_forward: ti.template(), \n",
    "    dx_backward: ti.template(), \n",
    "    dy_forward: ti.template(), \n",
    "    dy_backward: ti.template(), \n",
    "    abs_dx: ti.template(), \n",
    "    abs_dy: ti.template(),\n",
    "    ε: ti.f32,\n",
    "    dW_dt: ti.template(),\n",
    "    i_target: ti.i32,\n",
    "    j_target: ti.i32\n",
    ") -> ti.f32:\n",
    "    \"\"\"\n",
    "    @taichi.kernel\n",
    "\n",
    "    Update the (approximate) distance map `W` by a single step of the iterative \n",
    "    method described in Bekkers et al. in \"A PDE approach to Data-Driven Sub-\n",
    "    Riemannian Geodesics in SE(2)\" (2015).\n",
    "\n",
    "    Args:\n",
    "      Static:\n",
    "        `cost`: ti.field(dtype=[float], shape=shape) of cost function.\n",
    "        `d*_*`: ti.field(dtype=[float], shape=shape) of derivatives.\n",
    "        `ε`: \"Time\" step size, taking values greater than 0.\n",
    "        `*_target`: Indices of the target point.\n",
    "      Mutated:\n",
    "        `W`: ti.field(dtype=[float], shape=shape) of approximate distance map, \n",
    "          which is updated in place.\n",
    "        `dW_dt`: ti.field(dtype=[float], shape=shape) of error of the distance \n",
    "          map with respect to the Eikonal PDE, which is updated in place.\n",
    "        `abs_d*`: ti.field(dtype=[float], shape=shape) of absolute values of\n",
    "          derivatives, which are updated in place.\n",
    "\n",
    "    Returns:\n",
    "        Change in (approximate) distance map at target point.\n",
    "    \"\"\"\n",
    "    eik.derivativesR2.abs_derivatives(W, 1., dx_forward, dx_backward, dy_forward, dy_backward, abs_dx, abs_dy)\n",
    "    for I in ti.grouped(W):\n",
    "        # It seems like TaiChi does not allow negative exponents.\n",
    "        dW_dt[I] = 1 - (ti.math.sqrt((abs_dx[I] ** 2 + abs_dy[I] ** 2)) / cost[I])\n",
    "        W[I] += dW_dt[I] * ε\n",
    "    return dW_dt[i_target, j_target] * ε # adding this in makes it a bit slower."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The quality of the approximation spreads out from the source point. Hence, if we are interested only in the distance map to points that are not that far away (in terms of the true distance map), then we do not have to perform as many iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_iterative = iterative_method_retinal_R2(cost, source_point, target_point)\n",
    "# W_fast_marching = fast_marching_R2(cost) # Too slow..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all is well, then the distance map should be $0$ at the source point, and vary nicely around the source_point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_iterative[source_point[0]-3:source_point[0]+2, source_point[1]-3:source_point[1]+2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now visualise the distance map with a contour plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(12, 10))\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "fig.canvas.resizable = False\n",
    "ax.imshow(cost, cmap=\"gray\", origin=\"upper\")\n",
    "max_distance = np.round(W_iterative[target_point[1], target_point[0]] * 1.2)\n",
    "contour = ax.contour(xs, ys, W_iterative, levels=np.linspace(0., max_distance, 5))\n",
    "ax.scatter(xs[source_point], ys[source_point], label=\"Source\", marker=\".\")\n",
    "ax.scatter(xs[target_point], ys[target_point], label=\"Target\", marker=\".\")\n",
    "ax.set_xlabel(\"j\")\n",
    "ax.set_ylabel(\"i\")\n",
    "ax.set_xlim(j_min, j_max)\n",
    "ax.set_ylim(i_max, i_min)\n",
    "ax.legend()\n",
    "fig.colorbar(contour, label=\"W[i, j]\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geodesic tracking\n",
    "Now that we have the distance map (from a certain source point), we are able to compute the geodesics between the source point and any other point $(x^*, y^*)$ using backtracking:\n",
    "$$\\begin{dcases} \\dot{\\gamma}(t) = -\\left(\\frac{\\partial_x W(\\gamma(t))}{\\mathrm{cost}_{\\lambda, p}^2(\\gamma(t))}, \\frac{\\partial_y W(\\gamma(t))}{\\mathrm{cost}_{\\lambda, p}^2(\\gamma(t))}\\right), & t > 0, \\\\\n",
    "\\gamma(0) = (x^*, y^*). & \\end{dcases}$$\n",
    "We can numerically solve this using a Forward Euler discretisation:\n",
    "$$\\begin{dcases} \\gamma_{n + 1} = \\gamma_n - \\Delta t \\left(\\frac{\\partial_x W(\\gamma_n)}{\\mathrm{cost}_{\\lambda, p}^2(\\gamma_n)}, \\frac{\\partial_y W(\\gamma_n)}{\\mathrm{cost}_{\\lambda, p}^2(\\gamma_n)}\\right), & n > 0, \\\\\n",
    "\\gamma_0 = (x^*, y^*). & \\end{dcases}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodesic_back_tracking_retinal_R2(W_np, cost_np, source_point, target_point, β=0., n_max=10000):\n",
    "    \"\"\"\n",
    "    Find the geodesic conrnecting `target_point` to `source_point`, using\n",
    "    gradient descent backtracking, as described in Bekkers et al. \"A PDE \n",
    "    approach to Data-Driven Sub-Riemannian Geodesics in SE(2)\" (2015).\n",
    "\n",
    "    Args:\n",
    "        `W_np`: np.ndarray of (approximate) distance map\n",
    "        `cost_np`: np.ndarray of cost function.\n",
    "        `source_point`: Tuple[int] describing index of source point in `W_np`.\n",
    "        `target_point`: Tuple[int] describing index of target point in `W_np`.\n",
    "      Optional:\n",
    "        `β`: Momentum parameter in gradient descent, taking values between 0 and \n",
    "          1. Defaults to 0.\n",
    "        `n_max`: Maximum number of points in geodesic, taking positive integral\n",
    "          values. Defaults to 10000.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray of geodesic connecting `target_point` to `source_point`.\n",
    "    \"\"\"\n",
    "    dt = 100 * cost_np.min() ** 2 # What is a good step size?\n",
    "\n",
    "    W = ti.field(dtype=ti.f32, shape=W_np.shape)\n",
    "    W.from_numpy(W_np)    \n",
    "    cost = ti.field(dtype=ti.f32, shape=cost_np.shape)\n",
    "    cost.from_numpy(cost_np)\n",
    "\n",
    "    γ_list = ti.root.dynamic(ti.i, n_max)\n",
    "    γ = ti.Vector.field(n=2, dtype=ti.f32)\n",
    "    γ_list.place(γ)\n",
    "\n",
    "    source_point = ti.Vector(source_point, dt=ti.f32)\n",
    "    target_point = ti.Vector(target_point, dt=ti.f32)\n",
    "\n",
    "    γ_len = geodesic_back_tracking(W, cost, source_point, target_point, dt, n_max, β, γ)\n",
    "    γ_dense = ti.Vector.field(n=2, dtype=ti.f32, shape=γ_len)\n",
    "    print(f\"Geodesic consists of {γ_len} points.\")\n",
    "    sparse_to_dense(γ, γ_dense)\n",
    "\n",
    "    return γ_dense.to_numpy()\n",
    "\n",
    "@ti.kernel\n",
    "def geodesic_back_tracking(\n",
    "    W: ti.template(),\n",
    "    cost: ti.template(),\n",
    "    source_point: ti.types.vector(2, ti.f32), \n",
    "    target_point: ti.types.vector(2, ti.f32),\n",
    "    dt: ti.f32,\n",
    "    n_max: ti.i32,\n",
    "    β: ti.f32,\n",
    "    γ: ti.template()\n",
    ") -> ti.i32:\n",
    "    \"\"\"\n",
    "    @taichi.kernel\n",
    "\n",
    "    Find the geodesic connecting `target_point` to `source_point`, using\n",
    "    gradient descent backtracking, as described in Bekkers et al. \"A PDE \n",
    "    approach to Data-Driven Sub-Riemannian Geodesics in SE(2)\" (2015).\n",
    "\n",
    "    Args:\n",
    "      Static:\n",
    "        `W`: ti.field(dtype=[float], shape=shape) of (approximate) distance map.\n",
    "        `cost`: ti.field(dtype=[float], shape=shape) of cost function.\n",
    "        `dt`: Gradient descent step size, taking values greater than 0.\n",
    "        `source_point`: ti.types.vector(n=2, dtype=[float]) describing index of \n",
    "          source point in `W_np`.\n",
    "        `target_point`: ti.types.vector(n=2, dtype=[float]) describing index of \n",
    "          target point in `W_np`.\n",
    "        `n_max`: Maximum number of points in geodesic, taking positive integral\n",
    "          values. Defaults to 10000.\n",
    "        `β`: Momentum parameter in gradient descent, taking values between 0 and \n",
    "          1. Defaults to 0.\n",
    "        `*_target`: Indices of the target point.\n",
    "      Mutated:\n",
    "        `γ`: ti.Vector.field(n=2, dtype=[float]) of coordinates of points on the\n",
    "          geodesic. #SNode stuff#\n",
    "\n",
    "    Returns:\n",
    "        Number of points in the geodesic.\n",
    "    \"\"\"\n",
    "    point = target_point\n",
    "    γ.append(point)\n",
    "    tol = 1e-5\n",
    "    n = 0\n",
    "    gradient_at_point = compute_gradient(W, point, ti.Vector([0., 0.], dt=ti.f32), 0.)\n",
    "    while (ti.math.length(gradient_at_point) >= tol) and (n < n_max - 2):\n",
    "        cost_at_point = eik.derivativesR2.bilinear_interpolate(cost, point)\n",
    "        gradient_at_point = compute_gradient(W, point, gradient_at_point, β)\n",
    "        new_point = get_next_point(point, gradient_at_point, cost_at_point, dt)\n",
    "        γ.append(new_point)\n",
    "        point = new_point\n",
    "        n += 1\n",
    "    γ.append(source_point)\n",
    "    return γ.length()\n",
    "    \n",
    "@ti.func\n",
    "def compute_gradient(\n",
    "    W: ti.template(),\n",
    "    point: ti.types.vector(n=2, dtype=ti.f32),\n",
    "    old_gradient: ti.types.vector(n=2, dtype=ti.f32),\n",
    "    β: ti.f32\n",
    ") -> ti.types.vector(n=2, dtype=ti.f32):\n",
    "    \"\"\"\n",
    "    @taichi.func\n",
    "\n",
    "    Compute the gradient of the (approximate) distance map `W` with respect to\n",
    "    x-y coordinates at `point`.\n",
    "\n",
    "    Args:\n",
    "        `W`: ti.field(dtype=[float], shape=shape) of (approximate) distance map.\n",
    "        `point`: ti.types.vector(n=2, dtype=[float]) coordinates of current\n",
    "          point.\n",
    "        `old_gradient`: Gradient at previous point, for use with momentum.\n",
    "        `β`: Momentum parameter in gradient descent, taking values between 0 and \n",
    "          1.\n",
    "\n",
    "    Returns:\n",
    "        Gradient of the (approximate) distance map `W` with respect to x-y \n",
    "        coordinates at `point`.\n",
    "    \"\"\"\n",
    "    # Central Difference Derivatives\n",
    "    x_shift = ti.Vector([0.5, 0.], dt=ti.f32)\n",
    "    y_shift = ti.Vector([0., 0.5], dt=ti.f32)\n",
    "    W_x_forward = eik.derivativesR2.bilinear_interpolate(W, point + x_shift)\n",
    "    W_x_backward = eik.derivativesR2.bilinear_interpolate(W, point - x_shift)\n",
    "    W_y_forward = eik.derivativesR2.bilinear_interpolate(W, point + y_shift)\n",
    "    W_y_backward = eik.derivativesR2.bilinear_interpolate(W, point - y_shift)\n",
    "    gradient_x = (W_x_forward - W_x_backward)\n",
    "    gradient_y = (W_y_forward - W_y_backward)\n",
    "\n",
    "    # Upwind Derivatives\n",
    "    # x_shift = ti.Vector([1., 0.], dt=ti.f32)\n",
    "    # y_shift = ti.Vector([0., 1.], dt=ti.f32)\n",
    "    # W_point = eik.derivativesR2.bilinear_interpolate(W, point)\n",
    "    # W_x_forward = eik.derivativesR2.bilinear_interpolate(W, point + x_shift)\n",
    "    # W_x_backward = eik.derivativesR2.bilinear_interpolate(W, point - x_shift)\n",
    "    # W_y_forward = eik.derivativesR2.bilinear_interpolate(W, point + y_shift)\n",
    "    # W_y_backward = eik.derivativesR2.bilinear_interpolate(W, point - y_shift)\n",
    "    # dx_forward = W_x_forward - W_point\n",
    "    # dx_backward = W_point - W_x_backward\n",
    "    # gradient_x = ti.math.max(-dx_forward, dx_backward, 0.) * (-1.)**(dx_forward >= dx_backward)\n",
    "    # dy_forward = W_y_forward - W_point\n",
    "    # dy_backward = W_point - W_y_backward\n",
    "    # gradient_y = ti.math.max(-dy_forward, dy_backward, 0.) * (-1.)**(dy_forward >= dy_backward)\n",
    "\n",
    "    new_gradient_x = β * old_gradient[0] + (1 - β) * gradient_x\n",
    "    new_gradient_y = β * old_gradient[1] + (1 - β) * gradient_y\n",
    "    return ti.Vector([new_gradient_x, new_gradient_y], ti.f32)\n",
    "    \n",
    "@ti.func\n",
    "def get_next_point(\n",
    "    point: ti.types.vector(n=2, dtype=ti.f32), \n",
    "    gradient_at_point: ti.types.vector(n=2, dtype=ti.f32), \n",
    "    cost_at_point: ti.f32,\n",
    "    dt: ti.f32\n",
    ") -> ti.types.vector(n=2, dtype=ti.f32):\n",
    "    \"\"\"\n",
    "    @taichi.func\n",
    "\n",
    "    Compute the next point in the gradient descent.\n",
    "\n",
    "    Args:\n",
    "        `point`: ti.types.vector(n=2, dtype=[float]) coordinates of current \n",
    "          point.\n",
    "        `gradient_at_point`: ti.types.vector(n=2, dtype=[float]) value of \n",
    "          gradient at current point.\n",
    "        `cost_at_point`: Value of the cost function at current point, taking\n",
    "          values greater than 0.\n",
    "        `dt`: Gradient descent step size, taking values greater than 0.\n",
    "\n",
    "    Returns:\n",
    "        Next point in the gradient descent.\n",
    "    \"\"\"\n",
    "    new_point = ti.Vector([0., 0.], dt=ti.f32)\n",
    "    new_point[0] = point[0] - dt * gradient_at_point[0] / cost_at_point**2\n",
    "    new_point[1] = point[1] - dt * gradient_at_point[1] / cost_at_point**2\n",
    "    return new_point\n",
    "\n",
    "@ti.kernel\n",
    "def sparse_to_dense(\n",
    "    sparse_thing: ti.template(),\n",
    "    dense_thing: ti.template()\n",
    "):\n",
    "    \"\"\"\n",
    "    @taichi.func\n",
    "\n",
    "    Convert a sparse TaiChi object on an SNode into a dense object.\n",
    "\n",
    "    Args:\n",
    "      Static:\n",
    "        `sparse_thing`: Sparse TaiChi object.\n",
    "      Mutated:\n",
    "        `dense_thing`: Preinitialised dense TaiChi object of correct size, which\n",
    "          is updated in place.\n",
    "    \"\"\"\n",
    "    for I in ti.grouped(sparse_thing):\n",
    "        dense_thing[I] = sparse_thing[I]\n",
    "    sparse_thing.deactivate()\n",
    "\n",
    "def convert_continuous_indices_to_real_space(γ_ci_np, xs_np, ys_np):\n",
    "    \"\"\"\n",
    "    Convert the continuous indices in the geodesic `γ_ci_np` to the \n",
    "    corresponding real space coordinates described by `xs_np` and `ys_np`.\n",
    "    \"\"\"\n",
    "    γ_ci = ti.Vector.field(n=2, dtype=ti.f32, shape=γ_ci_np.shape[0])\n",
    "    γ_ci.from_numpy(γ_ci_np)\n",
    "    γ = ti.Vector.field(n=2, dtype=ti.f32, shape=γ_ci.shape)\n",
    "\n",
    "    xs = ti.field(dtype=ti.f32, shape=xs_np.shape)\n",
    "    xs.from_numpy(xs_np)\n",
    "    ys = ti.field(dtype=ti.f32, shape=ys_np.shape)\n",
    "    ys.from_numpy(ys_np)\n",
    "\n",
    "    continuous_indices_to_real(γ_ci, xs, ys, γ)\n",
    "\n",
    "    return γ.to_numpy()\n",
    "\n",
    "@ti.kernel\n",
    "def continuous_indices_to_real(\n",
    "    γ_ci: ti.template(),\n",
    "    xs: ti.template(),\n",
    "    ys: ti.template(),\n",
    "    γ: ti.template()\n",
    "):\n",
    "    \"\"\"\n",
    "    @taichi.kernel\n",
    "\n",
    "    Interpolate the real space coordinates described by `xs` and `ys` at the \n",
    "    continuous indices in `γ_ci`.\n",
    "    \"\"\"\n",
    "    for I in ti.grouped(γ_ci):\n",
    "        γ[I][0] = eik.derivativesR2.bilinear_interpolate(xs, γ_ci[I])\n",
    "        γ[I][1] = eik.derivativesR2.bilinear_interpolate(ys, γ_ci[I])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "γ_ci = geodesic_back_tracking_retinal_R2(W_iterative, cost, source_point, target_point, β=0.8, n_max=10000)\n",
    "γ = convert_continuous_indices_to_real_space(γ_ci, xs, ys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see from the visualisation below that the geodesic follows the vessel rather well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize=(14, 5))\n",
    "fig.canvas.toolbar_visible = False\n",
    "fig.canvas.header_visible = False\n",
    "fig.canvas.footer_visible = False\n",
    "fig.canvas.resizable = False\n",
    "\n",
    "ax[0].imshow(retinal_image_gray_ds, cmap=\"gray\")\n",
    "contour = ax[0].contour(xs, ys, W_iterative, levels=np.linspace(0., max_distance, 5))\n",
    "ax[0].plot(γ[:-1, 0], γ[:-1, 1], label=\"geodesic\", color=\"red\")\n",
    "ax[0].scatter(xs[source_point], ys[source_point], label=\"Source\", marker=\".\")\n",
    "ax[0].scatter(xs[target_point], ys[target_point], label=\"Target\", marker=\".\")\n",
    "ax[0].set_xlabel(\"j\")\n",
    "ax[0].set_ylabel(\"i\")\n",
    "ax[0].set_xlim(j_min, j_max)\n",
    "ax[0].set_ylim(i_max, i_min)\n",
    "ax[0].legend()\n",
    "fig.colorbar(contour, label=\"W[i, j]\")\n",
    "\n",
    "ax[1].imshow(retinal_image_gray_ds, cmap=\"gray\")\n",
    "contour = ax[1].contour(xs, ys, W_iterative, levels=np.linspace(0., max_distance, 5))\n",
    "ax[1].plot(γ[:, 0], γ[:, 1], label=\"geodesic\", color=\"red\")\n",
    "ax[1].scatter(xs[source_point], ys[source_point], label=\"Source\", marker=\".\")\n",
    "ax[1].scatter(xs[target_point], ys[target_point], label=\"Target\", marker=\".\")\n",
    "ax[1].set_xlabel(\"j\")\n",
    "ax[1].set_ylabel(\"i\")\n",
    "ax[1].set_xlim(100, 320)\n",
    "ax[1].set_ylim(340, 120)\n",
    "ax[1].legend()\n",
    "fig.colorbar(contour, label=\"W[i, j]\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
